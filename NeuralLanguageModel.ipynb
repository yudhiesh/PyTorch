{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralLanguageModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqBTmb5GvOFdzNAOiQ2DUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yudhiesh/PyTorch/blob/master/NeuralLanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytCC5sahOowK"
      },
      "source": [
        "import torch "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd0DMM7ZOscu"
      },
      "source": [
        "sentences = [\"Hi my name is Yudhiesh\", 'How are you doing today', 'Monday is a great day', 'I love to study NLP']"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUb2uzlbPBeg",
        "outputId": "9599e961-ea39-4a27-f9dd-c50f070f15d1"
      },
      "source": [
        "vocab = {} # map from word type to index\n",
        "inputs = [] # stores an indexified version of each sentence\n",
        "\n",
        "for sent in sentences:\n",
        "    sent_idxes = []\n",
        "    sent = sent.split() # tokenize w/ whitespace\n",
        "    for w in sent:\n",
        "        if w not in vocab:\n",
        "            vocab[w] = len(vocab) # add a new type to the vocab\n",
        "        sent_idxes.append(vocab[w])\n",
        "    inputs.append(sent_idxes)\n",
        "\n",
        "print(vocab)\n",
        "print(inputs)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Hi': 0, 'my': 1, 'name': 2, 'is': 3, 'Yudhiesh': 4, 'How': 5, 'are': 6, 'you': 7, 'doing': 8, 'today': 9, 'Monday': 10, 'a': 11, 'great': 12, 'day': 13, 'I': 14, 'love': 15, 'to': 16, 'study': 17, 'NLP': 18}\n",
            "[[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 3, 11, 12, 13], [14, 15, 16, 17, 18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1MhDf7bPaPM"
      },
      "source": [
        "# two things: 1. convert to LongTensors, 2. define inputs / outputs\n",
        "# Inputs are the sentences excluding the word we want to predict\n",
        "prefixes = torch.LongTensor([sent[:-1] for sent in inputs])\n",
        "# Labels are the words that we want to predict \n",
        "labels = torch.LongTensor([sent[-1] for sent in inputs])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9kuH0PcTsVm",
        "outputId": "f22d843b-bfa6-4378-d84b-92e72cc35a83"
      },
      "source": [
        "prefixes"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 5,  6,  7,  8],\n",
              "        [10,  3, 11, 12],\n",
              "        [14, 15, 16, 17]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHtRyEG2TvPa",
        "outputId": "401cd726-4070-4745-88f9-413aa99d47a9"
      },
      "source": [
        "labels"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4,  9, 13, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zr4xdOWTwsk",
        "outputId": "d61417df-34cb-4d75-9843-993964fe6bc0"
      },
      "source": [
        "class NLM(torch.nn.Module):\n",
        "  def __init__(self, d_embedding, d_hidden, window_size, len_vocab):\n",
        "        super(NLM, self).__init__() # init the base Module class\n",
        "        self.d_emb = d_embedding\n",
        "        self.embeddings = torch.nn.Embedding(len_vocab, d_embedding)\n",
        "        # concatenated embeddings > hidden\n",
        "        self.W_hid = torch.nn.Linear(d_embedding*window_size, d_hidden)\n",
        "        # hidden > output probability distribution over vocab\n",
        "        self.W_out = torch.nn.Linear(d_hidden, len_vocab)\n",
        "\n",
        "  def forward(self, input): # each input will be a batch of prefixes (in this case 4)\n",
        "      batch_size, window_size = input.size() # 4 x 4\n",
        "      embs = self.embeddings(input) # 4 x 4 x 5\n",
        "      print('embedding size:', embs.size())\n",
        "\n",
        "      # next,  we want to concatenate the prefix embeddings together\n",
        "      concat_embs = embs.view(batch_size, window_size * self.d_emb) # 4 x 20\n",
        "      print('concatenated embs size:', concat_embs.size())\n",
        "\n",
        "      hidden = self.W_hid(concat_embs)\n",
        "      outputs = self.W_out(hidden)\n",
        "      return outputs\n",
        "\n",
        "\n",
        "network = NLM(d_embedding=5, d_hidden=12, window_size=4, len_vocab=len(vocab))\n",
        "\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 0.1\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=network.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  logits = network(prefixes)\n",
        "  loss = loss_fn(logits, labels)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  print(f\"Epoch: {i}\\nLoss: {loss}\")\n",
        "  \n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 0\n",
            "Loss: 3.1679701805114746\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 1\n",
            "Loss: 2.8735785484313965\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 2\n",
            "Loss: 2.617265462875366\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 3\n",
            "Loss: 2.379495859146118\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 4\n",
            "Loss: 2.1488254070281982\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 5\n",
            "Loss: 1.9196674823760986\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 6\n",
            "Loss: 1.6906859874725342\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 7\n",
            "Loss: 1.4634395837783813\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 8\n",
            "Loss: 1.2418321371078491\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 9\n",
            "Loss: 1.0322176218032837\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 10\n",
            "Loss: 0.841982364654541\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 11\n",
            "Loss: 0.676127016544342\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 12\n",
            "Loss: 0.5358457565307617\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 13\n",
            "Loss: 0.42069897055625916\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 14\n",
            "Loss: 0.3300548791885376\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 15\n",
            "Loss: 0.2618824541568756\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 16\n",
            "Loss: 0.21205784380435944\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 17\n",
            "Loss: 0.17572058737277985\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 18\n",
            "Loss: 0.1487606167793274\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 19\n",
            "Loss: 0.128254234790802\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 20\n",
            "Loss: 0.1122577041387558\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 21\n",
            "Loss: 0.09949249029159546\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 22\n",
            "Loss: 0.08910438418388367\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 23\n",
            "Loss: 0.0805082619190216\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 24\n",
            "Loss: 0.0732923299074173\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 25\n",
            "Loss: 0.06715955585241318\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 26\n",
            "Loss: 0.06189126521348953\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 27\n",
            "Loss: 0.05732259154319763\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 28\n",
            "Loss: 0.05332745239138603\n",
            "embedding size: torch.Size([4, 4, 5])\n",
            "concatenated embs size: torch.Size([4, 20])\n",
            "Epoch: 29\n",
            "Loss: 0.0498078316450119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnpzRpQNWeBl",
        "outputId": "34fb587b-e49a-462c-a3d2-af5c91537ca1"
      },
      "source": [
        "# Make predictions \n",
        "\n",
        "rev_vocab = {value: key for key, value in vocab.items() }\n",
        "name = prefixes[0].unsqueeze(0) # Add batch dimension\n",
        "logits = network(name)\n",
        "probs = torch.nn.functional.softmax(logits, dim=1).squeeze(0)\n",
        "predicted = probs.argmax().item()\n",
        "next_word = rev_vocab[predicted]\n",
        "print(f\"Given the input: Hi my name is, the model predicts that the next word will be {next_word} with probability {probs[predicted]:4f}\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding size: torch.Size([1, 4, 5])\n",
            "concatenated embs size: torch.Size([1, 20])\n",
            "Given the input: Hi my name is, the model predicts that the next word will be Yudhiesh with probability 0.939876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rxX5deqYU2K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}